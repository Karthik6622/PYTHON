{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ab9d9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'cv::medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m equalized_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mequalizeHist(img)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Apply median blur for noise reduction\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m median_blur \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequalized_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Thresholding to create a binary mask of the cranium and brain\u001b[39;00m\n\u001b[0;32m     24\u001b[0m _, cranium_brain_mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(median_blur, \u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'cv::medianBlur'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 01.a. Enchancement and Segmentation - Single Image\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the ultrasound image\n",
    "img = cv2.imread('/Users/ankitasarkar/Desktop/05. Works/Patient00216_Plane3_2_of_5.jpg', 0)  \n",
    "# Read the image as grayscale\n",
    "\n",
    "# Apply histogram equalization to enhance contrast\n",
    "equalized_img = cv2.equalizeHist(img)\n",
    "\n",
    "# Apply median blur for noise reduction\n",
    "median_blur = cv2.medianBlur(equalized_img, 10)\n",
    "\n",
    "# Thresholding to create a binary mask of the cranium and brain\n",
    "_, cranium_brain_mask = cv2.threshold(median_blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(cranium_brain_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the contour with the largest area\n",
    "max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Create a blank mask image\n",
    "mask_image = np.zeros_like(img)\n",
    "\n",
    "# Draw the largest contour on the mask\n",
    "cv2.drawContours(mask_image, [max_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Create a circular mask centered at the image center\n",
    "center_x = img.shape[1] // 2\n",
    "center_y = img.shape[0] // 2\n",
    "radius = int(min(img.shape) * 0.4)  # Adjust the radius as needed\n",
    "cv2.circle(mask_image, (center_x, center_y), radius, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "output_image = cv2.bitwise_and(img, mask_image)\n",
    "\n",
    "# Find the bounding box of the largest contour\n",
    "x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "# Add padding to the bounding box\n",
    "padding = 20  # Adjust the padding size as needed\n",
    "x -= padding\n",
    "y -= padding\n",
    "w += 2 * padding\n",
    "h += 2 * padding\n",
    "\n",
    "# Ensure the bounding box is within the image boundaries\n",
    "x = max(0, x)\n",
    "y = max(0, y)\n",
    "w = min(w, img.shape[1] - x)\n",
    "h = min(h, img.shape[0] - y)\n",
    "\n",
    "# Crop the output image to the bounding box region\n",
    "output_image = output_image[y:y+h, x:x+w]\n",
    "\n",
    "# Enhance the output image\n",
    "enhanced_image = cv2.equalizeHist(output_image)\n",
    "\n",
    "# Display the enhanced output\n",
    "plt.imshow(enhanced_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # 01.a. Enchancement and Segmentation - Zenodo Data set of 3092 Images \n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = '/Users/ankitasarkar/Desktop/05. Works/01.JPG_Image'\n",
    "output_folder = '/Users/ankitasarkar/Desktop/05. Works/02.Enhancement and Segmentation'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each image in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    # Read the image as grayscale\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path, 0)\n",
    "\n",
    "    # Apply histogram equalization to enhance contrast\n",
    "    equalized_img = cv2.equalizeHist(img)\n",
    "\n",
    "    # Apply median blur for noise reduction\n",
    "    median_blur = cv2.medianBlur(equalized_img, 5)\n",
    "\n",
    "    # Thresholding to create a binary mask of the cranium and brain\n",
    "    _, cranium_brain_mask = cv2.threshold(median_blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(cranium_brain_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a blank mask image\n",
    "    mask_image = np.zeros_like(img)\n",
    "\n",
    "    # Draw the largest contour on the mask\n",
    "    cv2.drawContours(mask_image, [max_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Create a circular mask centered at the image center\n",
    "    center_x = img.shape[1] // 2\n",
    "    center_y = img.shape[0] // 2\n",
    "    radius = int(min(img.shape) * 0.4)  # Adjust the radius as needed\n",
    "    cv2.circle(mask_image, (center_x, center_y), radius, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    output_image = cv2.bitwise_and(img, mask_image)\n",
    "\n",
    "    # Find the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    # Add padding to the bounding box\n",
    "    padding = 20  # Adjust the padding size as needed\n",
    "    x -= padding\n",
    "    y -= padding\n",
    "    w += 2 * padding\n",
    "    h += 2 * padding\n",
    "\n",
    "    # Ensure the bounding box is within the image boundaries\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    w = min(w, img.shape[1] - x)\n",
    "    h = min(h, img.shape[0] - y)\n",
    "\n",
    "    # Crop the output image to the bounding box region\n",
    "    output_image = output_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Enhance the output image\n",
    "    enhanced_image = cv2.equalizeHist(output_image)\n",
    "\n",
    "    # Save the enhanced output image\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Processing completed.\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Original Enhancement Code \n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = '/Users/ankitasarkar/Desktop/05. Works/01.JPG_Image'\n",
    "\n",
    "\n",
    "# Output directory to save the results\n",
    "output_directory = '/Users/ankitasarkar/Desktop/05. Works/02.Enhancement and Segmentation'\n",
    "\n",
    "\n",
    "# Loop over all the images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    image_path = os.path.join(source_directory, filename)\n",
    "\n",
    "    # Read the image\n",
    "    input_img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply median blur\n",
    "    median_blur = cv2.medianBlur(img_gray, 5)\n",
    "\n",
    "    # Apply Laplacian\n",
    "    laplacian_out = cv2.Laplacian(median_blur, cv2.CV_8U, -1)\n",
    "\n",
    "    # Sharpen the image\n",
    "    img_sharpened = cv2.addWeighted(img_gray, 1.5, laplacian_out, -0.5, 0)\n",
    "\n",
    "    # Create a mask using Sobel operator\n",
    "    sobel_x = cv2.Sobel(median_blur, cv2.CV_16S, 1, 0, ksize=-1)\n",
    "    sobel_x_abs = cv2.convertScaleAbs(sobel_x)\n",
    "    sobel_y = cv2.Sobel(median_blur, cv2.CV_16S, 0, 1, ksize=-1)\n",
    "    sobel_y_abs = cv2.convertScaleAbs(sobel_y)\n",
    "    mask_image = cv2.bitwise_and(sobel_x_abs, sobel_y_abs)\n",
    "\n",
    "    # Combine the sharpened image and mask\n",
    "    final = cv2.addWeighted(img_sharpened, 1, mask_image, 0.5, 0)\n",
    "\n",
    "    # Save the final image to the output directory\n",
    "    output_path = os.path.join(output_directory, filename)\n",
    "    cv2.imwrite(output_path, final)\n",
    "\n",
    "\n",
    "# # 02. Segregation\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the dataset folder containing the images\n",
    "dataset_folder = '/Users/ankitasarkar/Desktop/05. Works/02.Enhancement and Segmentation'\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file = '/Users/ankitasarkar/Desktop/05. Works/00. Misc/FETAL_PLANES_DB_data v1.1.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Create the three separate folders for each plane\n",
    "output_folder_plane1 = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/01_Cere'\n",
    "output_folder_plane2 = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/02_Thalam'\n",
    "output_folder_plane3 = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/03_Ventri'\n",
    "\n",
    "# Create the output folders if they don't exist\n",
    "os.makedirs(output_folder_plane1, exist_ok=True)\n",
    "os.makedirs(output_folder_plane2, exist_ok=True)\n",
    "os.makedirs(output_folder_plane3, exist_ok=True)\n",
    "\n",
    "# Iterate over the rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    image_name = row['Image Name']\n",
    "    plane_name = row['Plane Name']\n",
    "\n",
    "    # Determine the destination folder based on the plane name\n",
    "    if plane_name == 'Trans-cerebellum':\n",
    "        destination_folder = output_folder_plane1\n",
    "    elif plane_name == 'Trans-thalamic':\n",
    "        destination_folder = output_folder_plane2\n",
    "    elif plane_name == 'Trans-ventricular':\n",
    "        destination_folder = output_folder_plane3\n",
    "    else:\n",
    "        # Skip the image if the plane name is not recognized\n",
    "        continue\n",
    "\n",
    "    # Construct the source and destination paths\n",
    "    source_path = os.path.join(dataset_folder, image_name)\n",
    "    destination_path = os.path.join(destination_folder, image_name)\n",
    "\n",
    "    # Copy the image to the destination folder\n",
    "    shutil.copy2(source_path, destination_path)\n",
    "\n",
    "print('Images segregation complete.')\n",
    "\n",
    "\n",
    "# # 03. Classification\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ## 03. Training the Model\n",
    "\n",
    "# ## 03.a. Trans_Cerebellum Plane\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Path to the folder containing the ultrasound images\n",
    "images_folder = '/Users/ankitasarkar/Desktop/05. Works/00. Misc/Resized'\n",
    "\n",
    "# Load and preprocess the ultrasound images\n",
    "images = []\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith(\".DS_Store\"):\n",
    "        continue\n",
    "    \n",
    "    image_path = os.path.join(images_folder, filename)\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = image.astype('float32') / 255.0\n",
    "        images.append(image)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {image_path}\")\n",
    "        print(e)\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images = train_test_split(images, test_size=0.1, random_state=42)\n",
    "\n",
    "# Rest of the code...\n",
    "# Create the autoencoder model\n",
    "model = models.Sequential([\n",
    "    # Encoder\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "\n",
    "    # Decoder\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(3, (3, 3), activation='linear', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_images, epochs=30, batch_size=32, validation_data=(test_images, test_images))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(test_images, test_images, verbose=0)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Save the model's architecture and weights\n",
    "model.save('/Users/ankitasarkar/Desktop/Model_Archi_Weight')\n",
    "\n",
    "# Generate reconstructed images\n",
    "reconstructed_images = model.predict(test_images)\n",
    "\n",
    "# Scale the reconstructed images back to the original range\n",
    "reconstructed_images = reconstructed_images * 255.0\n",
    "\n",
    "# Visualize original and reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 5  # Number of images to display\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # Original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Reconstructed image\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_images[i].astype('uint8'))  # Convert to uint8 for correct visualization\n",
    "    plt.title('Reconstructed')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model_path = '/Users/ankitasarkar/Desktop/Model_Archi_Weight'\n",
    "model = load_model(model_path)\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training and validation loss from the history object\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "plt.plot(epochs, training_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ## 03.a. Trans_Cerebellum Plane\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the folder containing the new ultrasound images\n",
    "new_images_folder = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/01_Cere'\n",
    "\n",
    "\n",
    "# Load and preprocess the new ultrasound images\n",
    "new_images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in os.listdir(new_images_folder):\n",
    "    if filename.endswith(\".DS_Store\"):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(new_images_folder, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float32') / 255.0\n",
    "\n",
    "    new_images.append(image)\n",
    "    image_names.append(filename)\n",
    "\n",
    "new_images = np.array(new_images)\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "normal_count = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "# Predict the labels for the new images\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Threshold to classify as normal or abnormal\n",
    "threshold = 0.15  # Adjust the threshold as needed\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i].mean() < threshold:\n",
    "        print(f\"{image_names[i]}: Abnormal\")\n",
    "        abnormal_count += 1\n",
    "    else:\n",
    "        print(f\"{image_names[i]}: Normal\")\n",
    "        normal_count += 1\n",
    "\n",
    "# Print the count of normal and abnormal predictions\n",
    "print(\"Normal Count:\", normal_count)\n",
    "print(\"Abnormal Count:\", abnormal_count)\n",
    "\n",
    "\n",
    "# ## 03.b. Trans-thalamic Plane\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the folder containing the new ultrasound images\n",
    "new_images_folder = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/02_Thalam'\n",
    "\n",
    "\n",
    "# Load and preprocess the new ultrasound images\n",
    "new_images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in os.listdir(new_images_folder):\n",
    "    if filename.endswith(\".DS_Store\"):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(new_images_folder, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float32') / 255.0\n",
    "\n",
    "    new_images.append(image)\n",
    "    image_names.append(filename)\n",
    "\n",
    "new_images = np.array(new_images)\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "normal_count = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "# Predict the labels for the new images\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Threshold to classify as normal or abnormal\n",
    "threshold = 0.15  # Adjust the threshold as needed\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i].mean() < threshold:\n",
    "        print(f\"{image_names[i]}: Abnormal\")\n",
    "        abnormal_count += 1\n",
    "    else:\n",
    "        print(f\"{image_names[i]}: Normal\")\n",
    "        normal_count += 1\n",
    "\n",
    "# Print the count of normal and abnormal predictions\n",
    "print(\"Normal Count:\", normal_count)\n",
    "print(\"Abnormal Count:\", abnormal_count)\n",
    "\n",
    "\n",
    "# ## 03.c. Trans_Ventricular Plane\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the folder containing the new ultrasound images\n",
    "new_images_folder = '/Users/ankitasarkar/Desktop/05. Works/03. Segregation/03_Ventri'\n",
    "\n",
    "\n",
    "# Load and preprocess the new ultrasound images\n",
    "new_images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in os.listdir(new_images_folder):\n",
    "    if filename.endswith(\".DS_Store\"):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(new_images_folder, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float32') / 255.0\n",
    "\n",
    "    new_images.append(image)\n",
    "    image_names.append(filename)\n",
    "\n",
    "new_images = np.array(new_images)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# Initialize counters\n",
    "normal_count = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "# Predict the labels for the new images\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Threshold to classify as normal or abnormal\n",
    "threshold = 0.15  # Adjust the threshold as needed\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i].mean() < threshold:\n",
    "        print(f\"{image_names[i]}: Abnormal\")\n",
    "        abnormal_count += 1\n",
    "    else:\n",
    "        print(f\"{image_names[i]}: Normal\")\n",
    "        normal_count += 1\n",
    "\n",
    "# Print the count of normal and abnormal predictions\n",
    "print(\"Normal Count:\", normal_count)\n",
    "print(\"Abnormal Count:\", abnormal_count)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583b12fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafb9f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(dataset_dir)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m train_images, test_images, train_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Create a deep learning model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     39\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     40\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m ])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Define your dataset directory\n",
    "dataset_dir = 'ronaldo.jfif'\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subdir, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                image_path = os.path.join(subdir, file)\n",
    "                # Load and preprocess the image using OpenCV\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (224, 224))  # Resize to match model input size\n",
    "                image = image.astype('float32') / 255.0\n",
    "                images.append(image)\n",
    "                # Extract label information from the directory structure or filename\n",
    "                label = 1 if 'abnormal' in subdir.lower() else 0\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "images, labels = load_and_preprocess_data(dataset_dir)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a deep learning model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Use the model for predictions\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Post-process the predictions and report the results\n",
    "for i in range(len(test_images)):\n",
    "    if predictions[i] > 0.5:\n",
    "        print(f\"Image {i}: Abnormal\")\n",
    "    else:\n",
    "        print(f\"Image {i}: Normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fba34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
